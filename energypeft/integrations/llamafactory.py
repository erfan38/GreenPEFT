import subprocess
import json
import yaml
from typing import Dict, Any, Optional

class LlamaFactoryEnergyWrapper:
    """Energy-aware wrapper for LlamaFactory"""
    
    def __init__(self, energy_framework, llamafactory_config: Optional[Dict] = None):
        self.energy_framework = energy_framework

        if llamafactory_config is not None and not isinstance(llamafactory_config, dict):
            raise TypeError("llamafactory_config must be a dictionary")
        
        self.config = llamafactory_config or {}
        
    def create_energy_config(self, 
                           model_name: str = "meta-llama/Llama-3.1-8B-Instruct",
                           dataset: str = "alpaca_gpt4_en",
                           output_dir: str = "./energy_efficient_llama") -> Dict[str, Any]:
        """Generate energy-optimized LlamaFactory config"""
        
        # Base energy-efficient configuration
        energy_config = {
            # Model settings
            "model_name_or_path": model_name,
            "template": "llama3",
            
            # Dataset settings  
            "dataset": dataset,
            "cutoff_len": 1024,
            
            # PEFT settings
            "finetuning_type": "lora",
            "lora_target": "q_proj,v_proj,k_proj,o_proj,gate_proj,up_proj,down_proj",
            "lora_rank": 16,
            "lora_alpha": 32,
            "lora_dropout": 0.05,
            
            # Energy-aware training settings
            "per_device_train_batch_size": 2,  # Smaller for energy efficiency
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 4,   # Compensate for smaller batch
            "num_train_epochs": 2,              # Fewer epochs
            "max_samples": 1000,                # Limited samples for energy budget
            
            # Optimization settings
            "learning_rate": 1e-4,
            "lr_scheduler_type": "cosine",
            "warmup_steps": 20,
            "max_grad_norm": 1.0,
            
            # Energy monitoring settings
            "logging_steps": 10,
            "save_steps": 100,
            "eval_steps": 50,
            "evaluation_strategy": "steps",
            "load_best_model_at_end": True,
            "save_total_limit": 2,
            
            # Output settings
            "output_dir": output_dir,
            "overwrite_output_dir": True,
            "overwrite_cache": True,
            
            # Hardware settings
            "quantization_bit": 4,  # 4-bit quantization for efficiency
            "report_to": "tensorboard"
        }
        
        # Update with user-provided config
        energy_config.update(self.config)
        
        return energy_config
    
    def train_with_energy_monitoring(self,
                                   config: Optional[Dict] = None,
                                   config_file: str = "energy_config.yaml") -> Dict[str, Any]:
        """Run LlamaFactory training with energy monitoring"""
        
        if config is None:
            config = self.create_energy_config()
            
        # Save config to file
        with open(config_file, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
            
        # Start energy monitoring
        self.energy_framework.energy_monitor.start_monitoring()
        
        try:
            # Run LlamaFactory training
            cmd = f"llamafactory-cli train {config_file}"
            
            print(f"ðŸŒ± Starting energy-aware training with {self.energy_framework.energy_monitor.energy_budget_wh}Wh budget")
            print(f"Command: {cmd}")
            
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"Training failed: {result.stderr}")
                
        finally:
            # Stop monitoring and get results
            metrics = self.energy_framework.energy_monitor.stop_monitoring()
            
            # Save energy report
            self.energy_framework.energy_monitor.save_energy_log("energy_report.json")
            
            print(f"\nðŸŽ‰ Training completed!")
            print(f"âš¡ Energy consumed: {metrics.total_energy_wh:.2f} Wh")
            print(f"ðŸ“Š Budget utilization: {metrics.budget_used_percent:.1f}%")
            
            return {
                "energy_consumed_wh": metrics.total_energy_wh,
                "budget_utilization": metrics.budget_used_percent,
                "config_used": config
            }
