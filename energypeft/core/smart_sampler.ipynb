{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cf2c1c-d427-4e8a-9e1a-1e30567cc2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/fatemeh/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/fatemeh/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fatemeh/miniconda3/envs/myenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.1-cp310-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m  \u001b[33m0:00:21\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [torch]━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [torch]]x]mpy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 fsspec-2025.10.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca232f64-d2db-475e-b299-42c64fcb3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d79050b-584f-4693-9083-0b010e321673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489628a8-1465-4936-8ac0-679c5328f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEfficiencyTracker:\n",
    "    \"\"\"Tracks Loss (Utility) and Length (Cost) to compute Value-per-Watt scores\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_size: int, alpha: float = 1.0, beta: float = 0.5, decay: float = 0.9):\n",
    "        self.dataset_size = dataset_size\n",
    "        self.alpha = alpha # Importance of high loss\n",
    "        self.beta = beta   # Importance of short length\n",
    "        self.decay = decay\n",
    "        \n",
    "        # Initialize scores to 1.0 so all samples have equal chance initially\n",
    "        self.efficiency_scores = np.ones(dataset_size, dtype=np.float32)\n",
    "        \n",
    "    def update_batch_outcomes(self, indices: List[int], losses: List[float], lengths: List[int]):\n",
    "        \"\"\"\n",
    "        Update scores based on the actual training result.\n",
    "        Equation: Score = Loss^alpha / Length^beta\n",
    "        \"\"\"\n",
    "        for idx, loss, length in zip(indices, losses, lengths):\n",
    "            if 0 <= idx < self.dataset_size:\n",
    "                # Avoid division by zero\n",
    "                safe_len = max(1, length)\n",
    "                \n",
    "                # Calculate Value-per-Watt\n",
    "                # High Loss = Good (Learn more)\n",
    "                # High Length = Bad (Costs more)\n",
    "                new_score = (loss ** self.alpha) / (safe_len ** self.beta)\n",
    "                \n",
    "                # Update with moving average to keep history stable\n",
    "                self.efficiency_scores[idx] = (\n",
    "                    self.decay * self.efficiency_scores[idx] + \n",
    "                    (1 - self.decay) * new_score\n",
    "                )\n",
    "    \n",
    "    def get_probabilities(self) -> np.ndarray:\n",
    "        \"\"\"Get normalized sampling probabilities\"\"\"\n",
    "        scores = self.efficiency_scores\n",
    "        # Softmax or simple normalization - simple normalization is faster\n",
    "        total_score = scores.sum()\n",
    "        if total_score > 0:\n",
    "            return scores / total_score\n",
    "        return np.ones_like(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f42bab-8b97-4147-af68-b2253bb290a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyAwareSampler:\n",
    "    \"\"\"\n",
    "    Samples data based on 'Value-per-Watt' (Loss/Length).\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, energy_monitor, base_batch_size=32):\n",
    "        self.dataset_size = len(dataset)\n",
    "        self.energy_monitor = energy_monitor\n",
    "        self.base_batch_size = base_batch_size\n",
    "        \n",
    "        # Replace Gradient tracker with Loss tracker\n",
    "        self.tracker = LossEfficiencyTracker(self.dataset_size)\n",
    "        \n",
    "        # Internal state\n",
    "        self.epoch_indices = list(range(self.dataset_size))\n",
    "        self.used_indices = set()\n",
    "\n",
    "    def update_batch_outcomes(self, indices, losses, lengths):\n",
    "        \"\"\"Pass feedback from Trainer to Tracker\"\"\"\n",
    "        self.tracker.update_batch_outcomes(indices, losses, lengths)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Standard PyTorch Sampler iterator.\n",
    "        1. Calculate Probabilities based on history.\n",
    "        2. Sample without replacement.\n",
    "        \"\"\"\n",
    "        # 1. Get probabilities from our Tracker (The \"Brain\")\n",
    "        probs = self.tracker.get_probabilities()\n",
    "        \n",
    "        # 2. Reset for new epoch\n",
    "        self.used_indices.clear()\n",
    "        remaining_indices = list(range(self.dataset_size))\n",
    "        \n",
    "        # 3. Yield batches\n",
    "        while len(remaining_indices) > 0:\n",
    "            batch_size = self.base_batch_size # (Or get from adaptive batcher)\n",
    "            \n",
    "            # Normalize probabilities for ONLY the remaining indices\n",
    "            current_probs = probs[remaining_indices]\n",
    "            current_probs = current_probs / current_probs.sum()\n",
    "            \n",
    "            # Select indices\n",
    "            selected_indices = np.random.choice(\n",
    "                remaining_indices, \n",
    "                size=min(len(remaining_indices), batch_size), \n",
    "                replace=False, \n",
    "                p=current_probs\n",
    "            )\n",
    "            \n",
    "            # Yield indices for this batch\n",
    "            yield from selected_indices\n",
    "            \n",
    "            # Remove used\n",
    "            for idx in selected_indices:\n",
    "                remaining_indices.remove(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893af446-a945-4702-9e49-041b5b63787b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
